# MiniGPT ðŸ¤–
- Making a GPT2 model from scratch using pretrained weights of gpt2
- Source code: https://colab.research.google.com/drive/1Y0-k0N8DBfk1vV9Pe-hIAb2TfVI8Oy29?usp=sharing
## Acheivements
- Achieved a score of 46.75 in Llama3 evaluation
## Futher improvements
- Intergrate QLoRA to reduce VRAM requirement and number of trainable parameters to  significant level

